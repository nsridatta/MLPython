{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8144 images belonging to 1 classes.\n",
      "Found 8041 images belonging to 1 classes.\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 36s 1s/step - loss: 0.0276 - acc: 0.9850 - val_loss: 1.5907e-07 - val_acc: 1.0000\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 39s 2s/step - loss: 1.9096e-06 - acc: 1.0000 - val_loss: 1.0000e-07 - val_acc: 1.0000\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 46s 2s/step - loss: 7.6654e-07 - acc: 1.0000 - val_loss: 1.0000e-07 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 38s 2s/step - loss: 6.6176e-07 - acc: 1.0000 - val_loss: 1.0000e-07 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 36s 1s/step - loss: 2.7283e-07 - acc: 1.0000 - val_loss: 1.0000e-07 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 36s 1s/step - loss: 1.0102e-07 - acc: 1.0000 - val_loss: 1.0000e-07 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 37s 1s/step - loss: 1.0039e-07 - acc: 1.0000 - val_loss: 1.0000e-07 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 35s 1s/step - loss: 1.3194e-07 - acc: 1.0000 - val_loss: 1.0000e-07 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 35s 1s/step - loss: 1.0000e-07 - acc: 1.0000 - val_loss: 1.0000e-07 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 36s 1s/step - loss: 1.0000e-07 - acc: 1.0000 - val_loss: 1.0000e-07 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# importing libraries \n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from keras.models import Sequential \n",
    "from keras.layers import Conv2D, MaxPooling2D \n",
    "from keras.layers import Activation, Dropout, Flatten, Dense \n",
    "from keras import backend as K \n",
    "\n",
    "#All images are 224*224 \n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "#-----------------Data Sets --------------------------#\n",
    "#Training and Testing data sets directories\n",
    "train_data_dir = 'Z:\\AI\\Datasets\\Training'\n",
    "test_data_dir = 'Z:\\AI\\Datasets\\Testing'\n",
    "\n",
    "#Training and testing sample sizes\n",
    "nb_train_samples = 400\n",
    "nb_test_samples = 100\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "\n",
    "if K.image_data_format() == 'channels_first': \n",
    "    input_shape = (3, img_width, img_height) \n",
    "else: \n",
    "    input_shape = (img_width, img_height, 3) \n",
    "\n",
    "#CNN Sequential Model\n",
    "model = Sequential() \n",
    "model.add(Conv2D(32, (2, 2), input_shape = input_shape)) \n",
    "model.add(Activation('relu')) \n",
    "model.add(MaxPooling2D(pool_size =(2, 2))) \n",
    "\n",
    "model.add(Conv2D(32, (2, 2))) \n",
    "model.add(Activation('relu')) \n",
    "model.add(MaxPooling2D(pool_size =(2, 2))) \n",
    "\n",
    "model.add(Conv2D(64, (2, 2))) \n",
    "model.add(Activation('relu')) \n",
    "model.add(MaxPooling2D(pool_size =(2, 2))) \n",
    "\n",
    "model.add(Flatten()) \n",
    "model.add(Dense(64)) \n",
    "model.add(Activation('relu')) \n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(1)) \n",
    "model.add(Activation('sigmoid')) \n",
    "\n",
    "model.compile(loss ='binary_crossentropy', optimizer ='rmsprop', metrics =['accuracy']) \n",
    "\n",
    "#Training and test ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator( rescale = 1. / 255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True) \n",
    "test_datagen = ImageDataGenerator(rescale = 1. / 255) \n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir, target_size =(img_width, img_height), \n",
    "    batch_size = batch_size, class_mode ='binary') \n",
    "\n",
    "test_generator = test_datagen.flow_from_directory( \n",
    "    test_data_dir, \n",
    "    target_size =(img_width, img_height), \n",
    "    batch_size = batch_size, class_mode ='binary') \n",
    "steps_per_epoch = nb_train_samples / batch_size\n",
    "\n",
    "#Fit the model with Training and test data with respective epochs and step size\n",
    "model.fit_generator(train_generator, \n",
    "    steps_per_epoch, \n",
    "    epochs = epochs, \n",
    "    validation_data = test_generator, \n",
    "    validation_steps = nb_test_samples / batch_size) \n",
    "\n",
    "#Saving the model\n",
    "#model.save_weights('model_saved.h5') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
